{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semester Projekt Big Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_countries = [\n",
    "    \"Afghanistan\", \"Albania\", \"Algeria\", \"Andorra\", \"Angola\", \"Antigua and Barbuda\",\n",
    "    \"Argentina\", \"Armenia\", \"Australia\", \"Austria\", \"Azerbaijan\", \"Bahamas\", \"Bahrain\",\n",
    "    \"Bangladesh\", \"Barbados\", \"Belarus\", \"Belgium\", \"Belize\", \"Benin\", \"Bhutan\", \"Bolivia\",\n",
    "    \"Bosnia and Herzegovina\", \"Botswana\", \"Brazil\", \"Brunei\", \"Bulgaria\", \"Burkina Faso\",\n",
    "    \"Burundi\", \"Cabo Verde\", \"Cambodia\", \"Cameroon\", \"Canada\", \"Central African Republic\",\n",
    "    \"Chad\", \"Chile\", \"China\", \"Colombia\", \"Comoros\", \"Congo\", \"Democratic Republic of the Congo\",\n",
    "    \"Congo, Republic of the\", \"Costa Rica\", \"Croatia\", \"Cuba\", \"Cyprus\", \"Czech Republic\",\n",
    "    \"Denmark\", \"Djibouti\", \"Dominica\", \"Dominican Republic\", \"Ecuador\", \"Egypt\", \"El Salvador\",\n",
    "    \"Equatorial Guinea\", \"Eritrea\", \"Estonia\", \"Eswatini\", \"Ethiopia\", \"Fiji\", \"Finland\",\n",
    "    \"France\", \"Gabon\", \"Gambia\", \"Georgia\", \"Germany\", \"Ghana\", \"Greece\", \"Grenada\",\n",
    "    \"Guatemala\", \"Guinea\", \"Guinea-Bissau\", \"Guyana\", \"Haiti\", \"Honduras\", \"Hungary\",\n",
    "    \"Iceland\", \"India\", \"Indonesia\", \"Iran\", \"Iraq\", \"Ireland\", \"Israel\", \"Italy\", \"Jamaica\",\n",
    "    \"Japan\", \"Jordan\", \"Kazakhstan\", \"Kenya\", \"Kiribati\", \"Korea, North\", \"Korea, South\",\n",
    "    \"Kuwait\", \"Kyrgyzstan\", \"Laos\", \"Latvia\", \"Lebanon\", \"Lesotho\", \"Liberia\", \"Libya\",\n",
    "    \"Liechtenstein\", \"Lithuania\", \"Luxembourg\", \"Madagascar\", \"Malawi\", \"Malaysia\", \"Maldives\",\n",
    "    \"Mali\", \"Malta\", \"Marshall Islands\", \"Mauritania\", \"Mauritius\", \"Mexico\", \"Micronesia\",\n",
    "    \"Moldova\", \"Monaco\", \"Mongolia\", \"Montenegro\", \"Morocco\", \"Mozambique\", \"Myanmar\", \"Namibia\",\n",
    "    \"Nauru\", \"Nepal\", \"Netherlands\", \"New Zealand\", \"Nicaragua\", \"Niger\", \"Nigeria\", \"North Macedonia\",\n",
    "    \"Norway\", \"Oman\", \"Pakistan\", \"Palau\", \"Panama\", \"Papua New Guinea\", \"Paraguay\", \"Peru\",\n",
    "    \"Philippines\", \"Poland\", \"Portugal\", \"Qatar\", \"Romania\", \"Russia\", \"Rwanda\", \"Saint Kitts and Nevis\",\n",
    "    \"Saint Lucia\", \"Saint Vincent and the Grenadines\", \"Samoa\", \"San Marino\", \"Sao Tome and Principe\",\n",
    "    \"Saudi Arabia\", \"Senegal\", \"Serbia\", \"Seychelles\", \"Sierra Leone\", \"Singapore\", \"Slovakia\",\n",
    "    \"Slovenia\", \"Solomon Islands\", \"Somalia\", \"South Africa\", \"South Sudan\", \"Spain\", \"Sri Lanka\",\n",
    "    \"Sudan\", \"Suriname\", \"Sweden\", \"Switzerland\", \"Syria\", \"Taiwan\", \"Tajikistan\", \"Tanzania\",\n",
    "    \"Thailand\", \"Timor-Leste\", \"Togo\", \"Tonga\", \"Trinidad and Tobago\", \"Tunisia\", \"Turkey\",\n",
    "    \"Turkmenistan\", \"Tuvalu\", \"Uganda\", \"Ukraine\", \"United Arab Emirates\", \"United Kingdom\",\n",
    "    \"United States\", \"Uruguay\", \"Uzbekistan\", \"Vanuatu\", \"Vatican City\", \"Venezuela\", \"Vietnam\",\n",
    "    \"Yemen\", \"Zambia\", \"Zimbabwe\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract country name from the breadcrumb link\n",
    "        breadcrumb_items = soup.find_all('a', class_='breadcrumb__item')\n",
    "        country = url\n",
    "        \n",
    "        # Iterate through each breadcrumb item to find a valid country\n",
    "        for item in breadcrumb_items:\n",
    "            country_candidate = item.get_text(strip=True)\n",
    "            if country_candidate in known_countries:\n",
    "                country = country_candidate\n",
    "                break\n",
    "        \n",
    "        table = soup.find('table', class_='aqi-overview-detail__other-pollution-table')\n",
    "        if table:\n",
    "            tbody = table.find('tbody')\n",
    "            if tbody:\n",
    "                rows = tbody.find_all('tr')\n",
    "                pollutants = []\n",
    "                for row in rows:\n",
    "                    columns = row.find_all('td')\n",
    "                    row_data = [col.get_text(strip=True) for col in columns]\n",
    "                    pollutants.append(row_data)\n",
    "                return {\n",
    "                    'country': country,\n",
    "                    'pollutants': pollutants\n",
    "                }\n",
    "        return {\n",
    "            'country': country,\n",
    "            'pollutants': []\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'country': 'Unknown',\n",
    "            'pollutants': []\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.iqair.com/world-air-quality-ranking\"\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    links = soup.find_all('a', {'class': 'city-label'})\n",
    "    for link in links:\n",
    "        city_url = \"https://www.iqair.com\" + link['href']\n",
    "        data = getData(city_url)\n",
    "        print(data)\n",
    "\n",
    "# Function to scrape data from a city page\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
